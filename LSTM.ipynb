{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vILc2k0ZcF0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import LongTensor\n",
    "from torch.nn import Embedding, LSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2Z1l7ovZzD0"
   },
   "outputs": [],
   "source": [
    "# Decoder\n",
    "#credit: https://gist.githubusercontent.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec/raw/60dc6be30ba57aa5d0d036e6af8ff702782ded18/pad_packed_demo.py\n",
    "## We want to run LSTM on a batch of 3 character sequences ['long_str', 'tiny', 'medium']\n",
    "#\n",
    "#     Step 1: Construct Vocabulary\n",
    "#     Step 2: Load indexed data (list of instances, where each instance is list of word indices)\n",
    "#     Step 3: Make Model\n",
    "#  *  Step 4: Pad instances with 0s till max length sequence\n",
    "#  *  Step 5: Sort instances by sequence length in descending order\n",
    "#  *  Step 6: Embed the instances\n",
    "#  *  Step 7: Call pack_padded_sequence with embeded instances and sequence lengths\n",
    "#  *  Step 8: Forward with LSTM\n",
    "#  *  Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector\n",
    "#  *  Summary of Shape Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIzKod1iZ521"
   },
   "outputs": [],
   "source": [
    "# We want to run LSTM on a batch following 3 character sequences\n",
    "seqs = ['a small sentence',  # len = 3\n",
    "        'little bit bigger sentence',      # len = 4\n",
    "        'nothing to say']    # len = 3\n",
    "test = 'new word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBj_Q7hxaFSc"
   },
   "outputs": [],
   "source": [
    "## Step 1: Construct Vocabulary ##\n",
    "##------------------------------##\n",
    "# make sure <pad> idx is 0\n",
    "vocab = ['<pad>', '<start>', '<end>', '<unk>'] + sorted(set([word for seq in seqs for word in seq.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "1YBFmR7OaU-D",
    "outputId": "55c9400c-4e30-4e4b-dcb2-16b4631b134f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<start>',\n",
       " '<end>',\n",
       " '<unk>',\n",
       " 'a',\n",
       " 'bigger',\n",
       " 'bit',\n",
       " 'little',\n",
       " 'nothing',\n",
       " 'say',\n",
       " 'sentence',\n",
       " 'small',\n",
       " 'to']"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ed2zeu2saRJ-",
    "outputId": "f4bf0c59-df43-4f20-d159-60ab00ab6ba1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 11, 10], [7, 6, 5, 10], [8, 12, 9]]"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 2: Load indexed data (list of instances, where each instance is list of character indices) ##\n",
    "##-------------------------------------------------------------------------------------------------##\n",
    "vectorized_seqs = [[vocab.index(tok) for tok in seq.split()]for seq in seqs]\n",
    "vectorized_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96m133RbaduM"
   },
   "outputs": [],
   "source": [
    "## Step 3: Make Model ##\n",
    "##--------------------##\n",
    "embed = Embedding(len(vocab), 4) # embedding_dim = 4\n",
    "lstm = LSTM(input_size=4, hidden_size=5, num_layers = 1, batch_first=True) # input_dim = 4, hidden_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHFPT15DakaG"
   },
   "outputs": [],
   "source": [
    "## Step 4: Pad instances with 0s till max length sequence ##\n",
    "##--------------------------------------------------------##\n",
    "\n",
    "# get the length of each seq in your batch\n",
    "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cIj1h-ZXg3kN",
    "outputId": "e4bae4ee-7058-4dd3-90ca-e4be6f0950c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 3])"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dz9rjmqeg2W2"
   },
   "outputs": [],
   "source": [
    "# seq_lengths => [3, 4, 3]\n",
    "# batch_sum_seq_len: 3 + 4 + 3 = 10\n",
    "# max_seq_len: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "F8hGYQQthDd9",
    "outputId": "35a05f7f-85e0-4f4d-d761-98784b13701e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfdIPYcKhIfC"
   },
   "outputs": [],
   "source": [
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = LongTensor(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Mm82r_qthMCx",
    "outputId": "b9bfdbf6-37d5-4223-d370-1312faa7ffd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 11, 10,  0],\n",
       "        [ 7,  6,  5, 10],\n",
       "        [ 8, 12,  9,  0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "9Ms1QmuGhqh-",
    "outputId": "2cf381db-8baa-4ec7-acbb-ffc2ee451a8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  6,  5, 10],\n",
       "        [ 4, 11, 10,  0],\n",
       "        [ 8, 12,  9,  0]])"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 5: Sort instances by sequence length in descending order ##\n",
    "##---------------------------------------------------------------##\n",
    "\n",
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "-wk2x_d8hwIA",
    "outputId": "74ab4789-4d69-4eea-8f0d-890a061929f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3227, -0.1044, -0.4612, -0.8055],\n",
       "         [-0.6661, -1.5316,  0.6446, -1.3370],\n",
       "         [-0.4653, -0.4362,  0.7046, -0.8728],\n",
       "         [-0.3567, -0.0277,  1.1684,  0.8097]],\n",
       "\n",
       "        [[ 0.6384,  0.5617,  0.6570,  1.0578],\n",
       "         [-0.2879,  2.3274,  0.8726,  1.0885],\n",
       "         [-0.3567, -0.0277,  1.1684,  0.8097],\n",
       "         [ 0.5068, -0.1829, -0.0915, -1.0838]],\n",
       "\n",
       "        [[-0.7129,  0.3673,  0.0192, -0.4796],\n",
       "         [-0.1367, -0.2717, -0.2533, -1.3797],\n",
       "         [ 0.9794, -0.4929, -1.6183, -0.6653],\n",
       "         [ 0.5068, -0.1829, -0.0915, -1.0838]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 6: Embed the instances ##\n",
    "##-----------------------------##\n",
    "\n",
    "embedded_seq_tensor = embed(seq_tensor)\n",
    "embedded_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Wst8PO0_m4KW",
    "outputId": "38e3185d-e016-4087-c1f1-6e3171aef8ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_seq_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "AnOJumDBh4lE",
    "outputId": "638e0a24-c8a2-4751-fa4e-624c439418bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3227, -0.1044, -0.4612, -0.8055],\n",
       "        [ 0.6384,  0.5617,  0.6570,  1.0578],\n",
       "        [-0.7129,  0.3673,  0.0192, -0.4796],\n",
       "        [-0.6661, -1.5316,  0.6446, -1.3370],\n",
       "        [-0.2879,  2.3274,  0.8726,  1.0885],\n",
       "        [-0.1367, -0.2717, -0.2533, -1.3797],\n",
       "        [-0.4653, -0.4362,  0.7046, -0.8728],\n",
       "        [-0.3567, -0.0277,  1.1684,  0.8097],\n",
       "        [ 0.9794, -0.4929, -1.6183, -0.6653],\n",
       "        [-0.3567, -0.0277,  1.1684,  0.8097]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>)"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 7: Call pack_padded_sequence with embeded instances and sequence lengths ##\n",
    "##-------------------------------------------------------------------------------##\n",
    "\n",
    "packed_input = pack_padded_sequence(embedded_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
    "# packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
    "packed_input.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4M7Q8d4kiEfd",
    "outputId": "74eed30e-8e9a-4855-9911-2bd04b3354f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input.data.shape #(batch_wise_sum_seq_len X embedding_dim) = (10 X 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6TQGYlSYnHFI",
    "outputId": "fd051b13-e4ce-4c89-a471-0fca2565db52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 1])"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_input.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QG9_OlwynL6R"
   },
   "outputs": [],
   "source": [
    "# visualization :\n",
    "# little  bit    longer    sentence\n",
    "# a       small  sentence \n",
    "# nothing to     say\n",
    "# 3  3  3  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdzNGPLHiAG0"
   },
   "outputs": [],
   "source": [
    "# tensor([[-0.3227, -0.1044, -0.4612, -0.8055], #little\n",
    "#         [ 0.6384,  0.5617,  0.6570,  1.0578], #a\n",
    "#         [-0.7129,  0.3673,  0.0192, -0.4796], #nothing\n",
    "\n",
    "#         [-0.6661, -1.5316,  0.6446, -1.3370], #bit\n",
    "#         [-0.2879,  2.3274,  0.8726,  1.0885], #small\n",
    "#         [-0.1367, -0.2717, -0.2533, -1.3797], #to\n",
    "\n",
    "#         [-0.4653, -0.4362,  0.7046, -0.8728], #bigger\n",
    "#         [-0.3567, -0.0277,  1.1684,  0.8097], #sentence\n",
    "#         [ 0.9794, -0.4929, -1.6183, -0.6653], #say\n",
    "\n",
    "#         [-0.3567, -0.0277,  1.1684,  0.8097]]) #sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mR947cXgnuYj"
   },
   "outputs": [],
   "source": [
    "## Step 8: Forward with LSTM ##\n",
    "##---------------------------##\n",
    "\n",
    "packed_output, (ht, ct) = lstm(packed_input)\n",
    "# packed_output (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOG-3vuDZ_rG"
   },
   "outputs": [],
   "source": [
    "# ## Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector ##\n",
    "# ##------------------------------------------------------------------------------------##\n",
    "\n",
    "# # unpack your output if required\n",
    "# output, input_sizes = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "# # output.shape : ( batch_size X max_seq_len X hidden_dim) = (3 X 4 X 5)\n",
    "\n",
    "# # Or if you just want the final hidden state?\n",
    "# print(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcMmBpYUbiR7"
   },
   "outputs": [],
   "source": [
    "## Summary of Shape Transformations ##\n",
    "##----------------------------------##\n",
    "\n",
    "# (batch_size X max_seq_len X embedding_dim) --> Sort by seqlen ---> (batch_size X max_seq_len X embedding_dim)\n",
    "# (batch_size X max_seq_len X embedding_dim) --->      Pack     ---> (batch_sum_seq_len X embedding_dim)\n",
    "# (batch_sum_seq_len X embedding_dim)        --->      LSTM     ---> (batch_sum_seq_len X hidden_dim)\n",
    "# (batch_sum_seq_len X hidden_dim)           --->    UnPack     ---> (batch_size X max_seq_len X hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pgsZeKOoDcS"
   },
   "outputs": [],
   "source": [
    "################ calculate loss ##############\n",
    "# there are two ways to calculate losses\n",
    "# using CrossEntropyLoss() = logSoftmax + NLLLoss()\n",
    "# using NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDAgW99xoSCE"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axUEjCiypK8S"
   },
   "outputs": [],
   "source": [
    "#lets assume for the sake of tutorial that targets = packed_input\n",
    "targets = seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "dPxf21QupTcN",
    "outputId": "1fc99b6c-dcfd-4f77-cb2a-90cb9569614e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  6,  5, 10],\n",
       "        [ 4, 11, 10,  0],\n",
       "        [ 8, 12,  9,  0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyNEhuNuqKmR"
   },
   "outputs": [],
   "source": [
    "targets = pack_padded_sequence(targets, seq_lengths.cpu().numpy(), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IA4ZsSloqak8",
    "outputId": "4cab18ee-cbc6-47f1-cd16-924ad31ec03d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([ 7,  4,  8,  6, 11, 12,  5, 10,  9, 10]), batch_sizes=tensor([3, 3, 3, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sDMajifp03_"
   },
   "outputs": [],
   "source": [
    "linear = nn.Linear(5, len(vocab)) #hidden_size, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8sopE0ep-ev"
   },
   "outputs": [],
   "source": [
    "outputs = linear(packed_output.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TQwHMX97qvxw",
    "outputId": "2cf4738f-0486-4cad-9ead-f98271752673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 13])"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7ojhyYLMo6di",
    "outputId": "d2ee1585-f8f6-4f0e-f128-cbdc65a8be9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6565, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(outputs, targets.data) \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "H8aDT7sApKQG",
    "outputId": "75fddaae-4be7-4f50-8726-485a29886950"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6565, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_2 = nn.NLLLoss()\n",
    "loss = criterion(F.log_softmax(outputs, dim=1), targets.data) \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCy26IYqrLBK"
   },
   "outputs": [],
   "source": [
    "########### Generation #################\n",
    "# For generating, you will want to generate one word at a time, but for tutorial's sake we are reusing the outputs generated above \n",
    "# to dicuss the main difference between two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD1E1lr_rn4C"
   },
   "outputs": [],
   "source": [
    "# Deterministic: get the maximum output from output at each step of generation\n",
    "_, predicted = outputs.max(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nNX-85RMtixb",
    "outputId": "96bca830-8c15-4631-f66c-4a705acddeec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 12,  6,  6,  2,  6,  6, 12,  6, 12])"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADGPTOjztBsk"
   },
   "outputs": [],
   "source": [
    "# Stochastic: sample from weighted softmax distribution\n",
    "temperature = 1\n",
    "probabilities = F.softmax(outputs.div(temperature).squeeze(0).squeeze(0), dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "nydZcTrEtWIT",
    "outputId": "1c4ca679-a66e-43b7-b6e7-bb19d427fe14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0848, 0.0966, 0.0742, 0.0749, 0.1030, 0.0428, 0.1172, 0.0500, 0.0893,\n",
       "         0.0898, 0.0450, 0.0534, 0.0792],\n",
       "        [0.0891, 0.0950, 0.0803, 0.0723, 0.1027, 0.0471, 0.0969, 0.0453, 0.0907,\n",
       "         0.1023, 0.0546, 0.0536, 0.0700],\n",
       "        [0.0878, 0.0987, 0.0765, 0.0682, 0.1032, 0.0438, 0.1025, 0.0504, 0.0965,\n",
       "         0.0934, 0.0488, 0.0509, 0.0792],\n",
       "        [0.0779, 0.0975, 0.0716, 0.0815, 0.1042, 0.0403, 0.1420, 0.0507, 0.0795,\n",
       "         0.0838, 0.0392, 0.0562, 0.0756],\n",
       "        [0.0884, 0.0920, 0.0820, 0.0677, 0.1129, 0.0442, 0.0857, 0.0464, 0.0889,\n",
       "         0.1124, 0.0541, 0.0527, 0.0727],\n",
       "        [0.0766, 0.0985, 0.0726, 0.0797, 0.1080, 0.0412, 0.1324, 0.0507, 0.0825,\n",
       "         0.0835, 0.0402, 0.0549, 0.0793],\n",
       "        [0.0782, 0.1004, 0.0735, 0.0798, 0.1036, 0.0413, 0.1389, 0.0502, 0.0805,\n",
       "         0.0850, 0.0411, 0.0561, 0.0715],\n",
       "        [0.0885, 0.0944, 0.0831, 0.0676, 0.1103, 0.0452, 0.0869, 0.0458, 0.0892,\n",
       "         0.1116, 0.0556, 0.0529, 0.0687],\n",
       "        [0.0745, 0.0888, 0.0684, 0.0928, 0.1061, 0.0404, 0.1510, 0.0476, 0.0725,\n",
       "         0.0816, 0.0365, 0.0588, 0.0811],\n",
       "        [0.0884, 0.0965, 0.0802, 0.0751, 0.1003, 0.0460, 0.1087, 0.0453, 0.0849,\n",
       "         0.1021, 0.0527, 0.0560, 0.0638]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "P66dfe2atNGY",
    "outputId": "667c80c2-f039-4d33-d861-9a6e6990b589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5],\n",
       "        [ 2],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [11],\n",
       "        [ 7],\n",
       "        [ 6],\n",
       "        [12],\n",
       "        [ 7]])"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.multinomial(probabilities.data, 1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "MkcuXzOVteiK",
    "outputId": "0225b3bd-b845-4b59-96d1-e12680214187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7],\n",
       "        [12],\n",
       "        [ 2],\n",
       "        [ 2],\n",
       "        [ 0],\n",
       "        [11],\n",
       "        [ 0],\n",
       "        [12],\n",
       "        [12],\n",
       "        [ 8]])"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.multinomial(probabilities.data, 1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbZsG2buwGYB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
